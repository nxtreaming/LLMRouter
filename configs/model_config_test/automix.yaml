# Config parameters for automix testing:


data_path:
  query_data_train: 'data/example_data/query_data/default_query_train.jsonl'
  query_data_test: 'data/example_data/query_data/default_query_test.jsonl'
  routing_data_train: 'data/example_data/routing_data/default_routing_train_data.jsonl'
  routing_data_test: 'data/example_data/routing_data/default_routing_test_data.jsonl'
  llm_data: 'data/example_data/llm_candidates/default_llm.json'
  llm_embedding_data: 'data/example_data/llm_candidates/default_llm_embeddings.json'

model_path:
  load_model_path: 'saved_models/automix/automix_model.pkl'


metric:
  weights:
    performance: 1
    cost: 0
    llm_judge: 0

hparam:
  routing_method: "POMDP"         # Routing method: "Threshold", "SelfConsistency", or "POMDP"
  num_bins: 8                     # Number of bins for discretization
  engine_small: "meta/llama-3.1-8b-instruct"    # Small model identifier
  engine_large: "meta/llama-3.1-70b-instruct"   # Large model identifier
  slm_column: "llama13b_f1"       # Column name for small model performance
  llm_column: "llama70b_f1"       # Column name for large model performance
  verifier_column: "p_ver_13b"    # Column name for verifier scores
  small_model_cost: 1             # Cost of using small model
  large_model_cost: 50            # Cost of using large model
  verifier_cost: 1                # Cost of using verifier
  device: "cpu"                   # Device for computation
  verbose: false                  # Whether to print verbose output
  cost_constraint: null           # Optional (min_cost, max_cost) tuple
  max_workers: 1                  # Number of parallel workers for API calls (increase for faster processing)





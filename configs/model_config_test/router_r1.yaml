# Config parameters for Router-R1:
#
# API Configuration:
#   You can configure api_base and api_key either:
#   1. In this YAML file (below)
#   2. Via environment variables:
#      - API Key: OPENAI_API_KEY, NVIDIA_API_KEY, NVAPI_KEY, or ROUTER_API_KEY
#      - API Base: OPENAI_API_BASE, NVIDIA_API_BASE, or ROUTER_API_BASE
#
# Example:
#   export OPENAI_API_KEY='your-api-key'
#   export OPENAI_API_BASE='https://api.openai.com/v1'


data_path:
  query_data_train: 'data/example_data/query_data/default_query_train.jsonl'
  query_data_test: 'data/example_data/query_data/default_query_test.jsonl'
  query_embedding_data: 'data/example_data/routing_data/query_embeddings_longformer.pt'
  routing_data_train: 'data/example_data/routing_data/default_routing_train_data.jsonl'
  routing_data_test: 'data/example_data/routing_data/default_routing_test_data.jsonl'
  llm_data: 'data/example_data/llm_candidates/default_llm.json'
  llm_embedding_data: 'data/example_data/llm_candidates/default_llm_embeddings.json'

metric:
  weights:
    performance: 1
    cost: 0
    llm_judge: 0


hparam:
  # Model ID from HF Repo:
  #   - "ulab-ai/Router-R1-Qwen2.5-3B-Instruct"
  #   - "ulab-ai/Router-R1-Qwen2.5-3B-Instruct-Alpha0.9"
  #   - "ulab-ai/Router-R1-Llama-3.2-3B-Instruct"
  #   - "ulab-ai/Router-R1-Llama-3.2-3B-Instruct-Alpha0.9"
  model_id: "ulab-ai/Router-R1-Qwen2.5-3B-Instruct"

  # API settings (leave empty to use environment variables)
  api_base: ""    # or set OPENAI_API_BASE / NVIDIA_API_BASE env var
  api_key: ""     # or set OPENAI_API_KEY / NVIDIA_API_KEY env var


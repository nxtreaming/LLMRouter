{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNMultiRoundRouter - Inference\n",
    "\n",
    "This notebook demonstrates how to use a trained **KNNMultiRoundRouter** for inference.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "The multi-round routing pipeline consists of:\n",
    "\n",
    "1. **Decompose**: Break complex queries into simpler sub-queries using LLM\n",
    "2. **Route**: Use trained KNN to route each sub-query to the best model\n",
    "3. **Execute**: Call the selected model API to get responses\n",
    "4. **Aggregate**: Combine all sub-responses into a final answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab\n",
    "import os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !git clone https://github.com/ulab-uiuc/LLMRouter.git\n",
    "    %cd LLMRouter\n",
    "    !pip install -e .\n",
    "    !pip install pyyaml scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "os.chdir(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmrouter.models.knnmultiroundrouter import KNNMultiRoundRouter\n",
    "from llmrouter.utils import setup_environment\n",
    "import yaml\n",
    "\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"configs/model_config_train/knnmultiroundrouter.yaml\"\n",
    "\n",
    "router = KNNMultiRoundRouter(yaml_path=CONFIG_PATH)\n",
    "print(\"Router loaded!\")\n",
    "\n",
    "# Load configuration\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Base model for decomposition: {config.get('base_model', 'Qwen/Qwen2.5-3B-Instruct')}\")\n",
    "print(f\"Use local LLM: {config.get('use_local_llm', False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Query Routing (Chat Mode)\n",
    "\n",
    "For simple string queries, the router returns just the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chat mode - pass string, get string response\n",
    "simple_query = \"What is the capital of France and what is its population?\"\n",
    "\n",
    "print(f\"Query: {simple_query}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    response = router.route_single(simple_query)\n",
    "    print(f\"\\nResponse:\\n{response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Note: Multi-round routing requires API access for execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Mode\n",
    "\n",
    "For evaluation with metrics, pass a dict with query, task_name, and ground_truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation mode - pass dict, get detailed result with metrics\n",
    "eval_query = {\n",
    "    \"query\": \"What is 15 * 23?\",\n",
    "    \"task_name\": \"math\",\n",
    "    \"ground_truth\": \"345\"\n",
    "}\n",
    "\n",
    "print(f\"Query: {eval_query['query']}\")\n",
    "print(f\"Task: {eval_query['task_name']}\")\n",
    "print(f\"Ground Truth: {eval_query['ground_truth']}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    result = router.route_single(eval_query)\n",
    "    \n",
    "    print(f\"\\nResponse: {result.get('response', 'N/A')}\")\n",
    "    print(f\"Success: {result.get('success', False)}\")\n",
    "    print(f\"Prompt Tokens: {result.get('prompt_tokens', 0)}\")\n",
    "    print(f\"Completion Tokens: {result.get('completion_tokens', 0)}\")\n",
    "    if 'task_performance' in result:\n",
    "        print(f\"Task Performance: {result['task_performance']:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing with multiple queries\n",
    "batch_queries = [\n",
    "    {\"query\": \"Explain photosynthesis.\"},\n",
    "    {\"query\": \"What causes earthquakes?\"},\n",
    "    {\"query\": \"How do computers work?\"},\n",
    "]\n",
    "\n",
    "print(f\"Processing {len(batch_queries)} queries...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    results = router.route_batch(batch_queries)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. Query: {result.get('query', 'N/A')[:50]}...\")\n",
    "        print(f\"   Success: {result.get('success', False)}\")\n",
    "        print(f\"   Response: {result.get('response', 'N/A')[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Understanding the Pipeline\n",
    "\n",
    "Let's examine the multi-round pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the pipeline components\n",
    "print(\"Multi-Round Pipeline Components:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. DECOMPOSITION\")\n",
    "print(\"   - Uses LLM to break complex query into sub-queries\")\n",
    "print(f\"   - Base model: {config.get('base_model', 'Qwen/Qwen2.5-3B-Instruct')}\")\n",
    "\n",
    "print(\"\\n2. ROUTING (KNN-based)\")\n",
    "print(f\"   - K value: {config['hparam']['n_neighbors']}\")\n",
    "print(f\"   - Distance metric: {config['hparam']['metric']}\")\n",
    "print(f\"   - Weight function: {config['hparam']['weights']}\")\n",
    "\n",
    "print(\"\\n3. EXECUTION\")\n",
    "print(\"   - Calls routed model API for each sub-query\")\n",
    "print(f\"   - API endpoint: {config.get('api_endpoint', 'Not configured')}\")\n",
    "\n",
    "print(\"\\n4. AGGREGATION\")\n",
    "print(\"   - Combines sub-query responses into final answer\")\n",
    "print(\"   - Uses LLM for intelligent synthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available LLM candidates for routing\n",
    "print(\"\\nAvailable LLM Candidates:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (name, info) in enumerate(router.llm_data.items(), 1):\n",
    "    size = info.get('size', 'unknown')\n",
    "    print(f\"{i}. {name}: {size}B parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmrouter.evaluator import Evaluator\n",
    "\n",
    "try:\n",
    "    evaluator = Evaluator(router=router)\n",
    "    metrics = evaluator.eval()\n",
    "\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    for metric_name, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{metric_name}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {value}\")\n",
    "except Exception as e:\n",
    "    print(f\"Evaluation requires API access: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 8. File-Based Inference\n\nLoad queries from a file and save results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import json\n\n# Load queries from a JSONL file\ndef load_queries_from_file(file_path):\n    \"\"\"Load queries from a JSONL file.\"\"\"\n    queries = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            if line.strip():\n                queries.append(json.loads(line))\n    return queries\n\n# Save results to a JSONL file\ndef save_results_to_file(results, output_path):\n    \"\"\"Save routing results to a JSONL file.\"\"\"\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    with open(output_path, 'w', encoding='utf-8') as f:\n        for result in results:\n            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n    print(f\"Results saved to: {output_path}\")\n\n# Example: Load from default query file\nQUERY_FILE = \"data/example_data/query_data/default_query_test.jsonl\"\nOUTPUT_FILE = \"outputs/knnmultiroundrouter_results.jsonl\"\n\nif os.path.exists(QUERY_FILE):\n    # Load queries\n    file_queries = load_queries_from_file(QUERY_FILE)\n    print(f\"Loaded {len(file_queries)} queries from: {QUERY_FILE}\")\n    \n    # Route queries (limit to 5 for demo due to API costs)\n    try:\n        file_results = router.route_batch(file_queries[:5])\n        print(f\"Routed {len(file_results)} queries\")\n        \n        # Save results\n        save_results_to_file(file_results, OUTPUT_FILE)\n        \n        # Show sample results\n        print(f\"\\nSample results:\")\n        for i, result in enumerate(file_results[:3], 1):\n            print(f\"  {i}. {result.get('query', '')[:40]}...\")\n            print(f\"     Success: {result.get('success', False)}\")\n    except Exception as e:\n        print(f\"Error during batch routing: {e}\")\nelse:\n    print(f\"Query file not found: {QUERY_FILE}\")\n    print(\"Create a JSONL file with format: {\\\"query\\\": \\\"Your question\\\"}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**KNNMultiRoundRouter** provides:\n",
    "- Query decomposition for complex questions\n",
    "- KNN-based routing for each sub-query\n",
    "- Parallel execution across multiple models\n",
    "- Intelligent response aggregation\n",
    "\n",
    "**Use Cases**:\n",
    "- Complex questions requiring multiple expertise areas\n",
    "- Multi-step reasoning tasks\n",
    "- Questions that benefit from specialized models\n",
    "\n",
    "**Requirements**:\n",
    "- Trained KNN model (from training notebook)\n",
    "- API access for LLM execution\n",
    "- Optional: vLLM for local decomposition/aggregation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EloRouter - Inference\n",
    "\n",
    "This notebook demonstrates how to use **EloRouter** for inference.\n",
    "\n",
    "## Overview\n",
    "\n",
    "EloRouter uses Elo ratings to select the best LLM. It's an inference-only router\n",
    "that doesn't require training - it uses pre-computed Elo ratings from benchmarks.\n",
    "\n",
    "**Key Features**:\n",
    "- No training required\n",
    "- Uses established Elo rating system\n",
    "- Simple and interpretable\n",
    "- Based on pairwise comparisons\n",
    "\n",
    "**Note**: EloRouter always selects the highest-rated LLM based on Elo scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmrouter.models.elorouter import EloRouter\n",
    "from llmrouter.utils import setup_environment\n",
    "\n",
    "setup_environment()\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "CONFIG_PATH = \"configs/model_config_train/elorouter.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Current Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "router = EloRouter(yaml_path=CONFIG_PATH)\n",
    "\n",
    "print(\"Router initialized successfully!\")\n",
    "print(f\"Number of LLM candidates: {len(router.llm_data)}\")\n",
    "print(f\"LLM candidates: {list(router.llm_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding Elo Ratings\n",
    "\n",
    "Elo rating system:\n",
    "- Higher rating = better model\n",
    "- Ratings updated based on pairwise comparisons\n",
    "- Used in Chatbot Arena leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Elo ratings for each LLM\n",
    "print(\"LLM Elo Ratings:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Note: Elo ratings should be available in the router or LLM data\n",
    "if hasattr(router, 'elo_ratings'):\n",
    "    for model, rating in sorted(router.elo_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {model:30} {rating}\")\n",
    "else:\n",
    "    print(\"Elo ratings are computed from benchmark data.\")\n",
    "    print(\"The router will select the model with highest average performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_QUERIES = [\n",
    "    {\"query\": \"What is the capital of France?\"},\n",
    "    {\"query\": \"Solve the equation: 2x + 5 = 15\"},\n",
    "    {\"query\": \"Write a Python function to check if a number is prime.\"},\n",
    "    {\"query\": \"Explain quantum computing in simple terms.\"},\n",
    "]\n",
    "\n",
    "print(\"Routing Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(EXAMPLE_QUERIES, 1):\n",
    "    result = router.route_single(query)\n",
    "    print(f\"{i}. {query['query'][:50]}...\")\n",
    "    print(f\"   Routed to: {result['model_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Note on EloRouter Behavior\n",
    "\n",
    "EloRouter is a **static** router - it always selects the same LLM (the highest-rated one)\n",
    "regardless of the query content. This is useful as:\n",
    "- A baseline for comparison\n",
    "- When you want the overall best model\n",
    "- When query-specific routing isn't necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify static behavior\n",
    "results = [router.route_single(q)['model_name'] for q in EXAMPLE_QUERIES]\n",
    "all_same = len(set(results)) == 1\n",
    "\n",
    "print(f\"All queries routed to same model: {all_same}\")\n",
    "if all_same:\n",
    "    print(f\"Selected model: {results[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 7. File-Based Inference\n\nLoad queries from a file and save results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import json\n\n# Load queries from a JSONL file\ndef load_queries_from_file(file_path):\n    \"\"\"Load queries from a JSONL file.\"\"\"\n    queries = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            if line.strip():\n                queries.append(json.loads(line))\n    return queries\n\n# Save results to a JSONL file\ndef save_results_to_file(results, output_path):\n    \"\"\"Save routing results to a JSONL file.\"\"\"\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    with open(output_path, 'w', encoding='utf-8') as f:\n        for result in results:\n            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n    print(f\"Results saved to: {output_path}\")\n\n# Example: Load from default query file\nQUERY_FILE = \"data/example_data/query_data/default_query_test.jsonl\"\nOUTPUT_FILE = \"outputs/elorouter_results.jsonl\"\n\nif os.path.exists(QUERY_FILE):\n    # Load queries\n    file_queries = load_queries_from_file(QUERY_FILE)\n    print(f\"Loaded {len(file_queries)} queries from: {QUERY_FILE}\")\n    \n    # Route queries\n    file_results = router.route_batch(batch=file_queries[:10])\n    print(f\"Routed {len(file_results)} queries\")\n    \n    # Save results\n    save_results_to_file(file_results, OUTPUT_FILE)\n    \n    # Show sample results\n    print(f\"\\nSample results:\")\n    for i, result in enumerate(file_results[:3], 1):\n        print(f\"  {i}. {result.get('query', '')[:40]}... -> {result['model_name']}\")\nelse:\n    print(f\"Query file not found: {QUERY_FILE}\")\n    print(\"Create a JSONL file with format: {\\\"query\\\": \\\"Your question\\\"}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Loaded EloRouter**: No training required\n",
    "2. **Understood Elo System**: Rating-based model selection\n",
    "3. **Performed Routing**: Static selection of best-rated model\n",
    "\n",
    "**Key Takeaways**:\n",
    "- EloRouter is the simplest router (no training)\n",
    "- Always selects the highest-rated model\n",
    "- Useful as a baseline or when simplicity is preferred\n",
    "\n",
    "**When to use EloRouter**:\n",
    "- As a baseline for comparison\n",
    "- When you always want the \"best\" model\n",
    "- When computational resources are limited\n",
    "\n",
    "**When NOT to use EloRouter**:\n",
    "- When query-specific routing is important\n",
    "- When cost optimization is needed\n",
    "- When different queries need different model capabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMRouter Quick Start Tutorial\n",
    "\n",
    "**Estimated Time:** 15 minutes  \n",
    "**Level:** Beginner  \n",
    "**Prerequisites:** None\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ulab-uiuc/LLMRouter/blob/main/tutorials/notebooks/00_Quick_Start.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- ‚úÖ Install LLMRouter in Google Colab\n",
    "- ‚úÖ Understand basic routing concepts\n",
    "- ‚úÖ Run your first inference\n",
    "- ‚úÖ Try different built-in routers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, let's install LLMRouter from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/ulab-uiuc/LLMRouter.git\n",
    "%cd LLMRouter\n",
    "\n",
    "# Install the package\n",
    "!pip install -e . -q\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding LLMRouter\n",
    "\n",
    "**What is LLMRouter?**\n",
    "\n",
    "LLMRouter is an intelligent system that automatically selects the best LLM for each query based on:\n",
    "- **Task complexity**: Simple queries ‚Üí smaller models, complex queries ‚Üí larger models\n",
    "- **Cost optimization**: Balance performance and cost\n",
    "- **Performance requirements**: Speed vs accuracy trade-offs\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "1. **Router**: Algorithm that decides which LLM to use\n",
    "2. **Query**: Your input question/prompt\n",
    "3. **LLM Candidates**: Pool of available models to choose from\n",
    "4. **Routing Decision**: Which model is selected and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. List Available Routers\n",
    "\n",
    "Let's see what routers are available out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!llmrouter list-routers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Your First Routing - Route Only\n",
    "\n",
    "Let's use a simple router (SmallestLLM) to make a routing decision without actually calling any LLM API.\n",
    "\n",
    "This is useful for:\n",
    "- Testing routing logic\n",
    "- Understanding router behavior\n",
    "- Avoiding API costs during development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route a simple query\n",
    "!llmrouter infer \\\n",
    "  --router smallest_llm \\\n",
    "  --config configs/model_config_test/smallest_llm.yaml \\\n",
    "  --query \"What is 2+2?\" \\\n",
    "  --route-only \\\n",
    "  --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the Output:**\n",
    "\n",
    "The router returns:\n",
    "- `model_name`: Which LLM was selected\n",
    "- `query`: Your original query\n",
    "- Additional metadata (depends on router type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try Different Routers\n",
    "\n",
    "Let's compare how different routers make decisions for the same query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of routers to try\n",
    "routers = [\n",
    "    ('smallest_llm', 'configs/model_config_test/smallest_llm.yaml'),\n",
    "    ('largest_llm', 'configs/model_config_test/largest_llm.yaml'),\n",
    "    ('knnrouter', 'configs/model_config_test/knnrouter.yaml'),\n",
    "]\n",
    "\n",
    "query = \"Explain quantum computing in simple terms\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for router_name, config_path in routers:\n",
    "    print(f\"\\nüîç Router: {router_name}\")\n",
    "    !llmrouter infer \\\n",
    "      --router {router_name} \\\n",
    "      --config {config_path} \\\n",
    "      --query \"{query}\" \\\n",
    "      --route-only \\\n",
    "      --verbose 2>&1 | grep -E \"(Routed to|model_name)\"\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Inference (Multiple Queries)\n",
    "\n",
    "Let's route multiple queries at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file with multiple queries\n",
    "queries = [\n",
    "    \"What is 2+2?\",\n",
    "    \"Explain quantum computing\",\n",
    "    \"Write a Python function to sort a list\",\n",
    "    \"Translate 'hello' to Spanish\",\n",
    "    \"What is the meaning of life?\"\n",
    "]\n",
    "\n",
    "# Save to file\n",
    "with open('test_queries.txt', 'w') as f:\n",
    "    for q in queries:\n",
    "        f.write(q + '\\n')\n",
    "\n",
    "print(\"‚úÖ Created test_queries.txt with\", len(queries), \"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route all queries\n",
    "!llmrouter infer \\\n",
    "  --router knnrouter \\\n",
    "  --config configs/model_config_test/knnrouter.yaml \\\n",
    "  --input test_queries.txt \\\n",
    "  --output results.json \\\n",
    "  --route-only \\\n",
    "  --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "import json\n",
    "\n",
    "with open('results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Pretty print results\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. Query: {result['query'][:50]}...\")\n",
    "    print(f\"   ‚Üí Routed to: {result.get('model_name', 'N/A')}\")\n",
    "    print(f\"   Success: {result['success']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Understanding Configuration Files\n",
    "\n",
    "Let's examine what's in a router configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a config file\n",
    "!cat configs/model_config_test/knnrouter.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Configuration Sections:**\n",
    "\n",
    "1. **`data_path`**: Paths to data files\n",
    "   - `llm_data`: Available LLM models\n",
    "   - `query_data_test`: Test queries\n",
    "   - `routing_data_test`: Ground truth routing labels\n",
    "\n",
    "2. **`model_path`**: Where to save/load trained models\n",
    "\n",
    "3. **`metric.weights`**: How to evaluate routing decisions\n",
    "   - Performance, cost, LLM judge scores\n",
    "\n",
    "4. **`hparam`**: Router-specific hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Examining LLM Candidates\n",
    "\n",
    "Let's see what LLM models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load LLM data\n",
    "with open('data/example_data/llm_candidates/default_llm.json', 'r') as f:\n",
    "    llm_data = json.load(f)\n",
    "\n",
    "print(f\"Total LLM models available: {len(llm_data)}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_info in llm_data.items():\n",
    "    print(f\"\\nüì¶ {model_name}\")\n",
    "    print(f\"   Model: {model_info.get('model', 'N/A')}\")\n",
    "    print(f\"   Size: {model_info.get('size', 'N/A')}\")\n",
    "    if 'cost' in model_info:\n",
    "        print(f\"   Cost: ${model_info['cost']}/1K tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "üéâ Congratulations! You've completed the Quick Start tutorial!\n",
    "\n",
    "### What You Learned:\n",
    "- ‚úÖ How to install LLMRouter\n",
    "- ‚úÖ Basic routing concepts\n",
    "- ‚úÖ Using different routers\n",
    "- ‚úÖ Batch inference\n",
    "- ‚úÖ Configuration files\n",
    "\n",
    "### Recommended Next Tutorials:\n",
    "\n",
    "1. **[01_Installation_and_Setup.ipynb](01_Installation_and_Setup.ipynb)** - Deep dive into setup\n",
    "2. **[02_Data_Preparation.ipynb](02_Data_Preparation.ipynb)** - Understanding data formats\n",
    "3. **[03_Training_Single_Round_Routers.ipynb](03_Training_Single_Round_Routers.ipynb)** - Train your first router\n",
    "\n",
    "### Additional Resources:\n",
    "- üìñ [Main Documentation](https://github.com/ulab-uiuc/LLMRouter)\n",
    "- üí¨ [Slack Community](https://join.slack.com/t/llmrouteropen-ri04588/shared_invite/...)\n",
    "- üêõ [GitHub Issues](https://github.com/ulab-uiuc/LLMRouter/issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercises (Optional)\n",
    "\n",
    "Try these to reinforce your learning:\n",
    "\n",
    "**Exercise 1:** Create your own list of 10 queries and route them using 3 different routers. Compare the results.\n",
    "\n",
    "**Exercise 2:** Examine the `data/example_data/routing_data/default_routing_test_data.jsonl` file. What information does it contain?\n",
    "\n",
    "**Exercise 3:** Modify a configuration file to change the metric weights. How does this affect routing decisions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
